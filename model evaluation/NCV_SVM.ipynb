{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bb446-8a3e-4ad6-b31e-10ac8427992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import set_config\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 85)\n",
    "sns.set_theme(context=\"paper\", font_scale=1.5, style=\"ticks\", rc={\"axes.grid\": True})\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0e2a2-6f5b-4e7c-a34a-4772b4962907",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Support Vector Machine: Scoring by Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f092e2-90d0-4451-80e3-507277fd459e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ebd87-bc4c-4952-8e97-4258c990d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data (NEW from PP)\n",
    "df = pd.read_csv(\"../data/new_abnormal_writeout_noscale.data.csv\", index_col=0)\n",
    "\n",
    "# Drop NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Collect Features and Labels\n",
    "features_df = pd.DataFrame()\n",
    "conf = df.drop(labels=[\"response\", \"occ_total_sum\", \"oldest_phylostratum\"], axis=1)\n",
    "\n",
    "features_df[\"occ_total_sum\"] = df[\"occ_total_sum\"]\n",
    "features_df[\"oldest_phylostratum\"] = df[\"oldest_phylostratum\"]\n",
    "features_df = pd.concat([features_df, conf], axis=1)\n",
    "\n",
    "X = features_df.to_numpy()\n",
    "y = df[\"response\"].to_numpy()\n",
    "X = np.ascontiguousarray(X)\n",
    "y = np.ascontiguousarray(y)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3421c3d-9bde-429c-8f54-a55788eb9b5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "*** \n",
    "## Nested CV on Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02804817-7683-43d5-9558-c04d61965569",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Model and its Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff279b-b7c0-4ed6-93ef-b3c7838ec539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Confounder PCA as ColumnTransformer\n",
    "confpca = ColumnTransformer(\n",
    "    [(\"ots+of\", \"passthrough\", [0, 1]), (\"conf\", PCA(), slice(2, X.shape[1]))]\n",
    ")\n",
    "\n",
    "# Parameter Grid\n",
    "main_params = {\n",
    "    \"svm__C\": np.logspace(-3, 3, 3),\n",
    "    \"svm__gamma\": np.logspace(-3, 3, 3),\n",
    "    \"svm__class_weight\": [\"balanced\", None],\n",
    "}\n",
    "\n",
    "pca_on = {\"pca\": [confpca], \"pca__conf__n_components\": [None, 0.95]}\n",
    "pca_off = {\n",
    "    \"pca\": [\"passthrough\"],\n",
    "}\n",
    "\n",
    "param_grid = [{**main_params, **pca_on}, {**main_params, **pca_off}]\n",
    "\n",
    "# Model as Pipeline\n",
    "svm_clf = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", confpca),\n",
    "        (\"svm\", SVC(kernel=\"rbf\", cache_size=4000, probability=True)), \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387f1a4-c000-4bc7-b156-c204e7abc26e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc8f13-b73d-4f21-99f0-36a04a5047dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "np.random.seed(4)\n",
    "model = svm_clf\n",
    "k_outer = 10\n",
    "k_inner = 3\n",
    "cv_outer = KFold(n_splits=k_outer, shuffle=True)\n",
    "cv_inner = KFold(n_splits=k_inner, shuffle=True)\n",
    "\n",
    "# To store results\n",
    "roc_results = list()\n",
    "found_params = list()\n",
    "\n",
    "print(f\"Performing nested-cv with {k_outer} outer-folds and {k_inner} inner-folds.\\n\")\n",
    "print(\"OUTER CV | BEST OF INNER CV | CHOSEN PARAMS\")\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "\n",
    "    # split data\n",
    "    X_tr, X_te = X[train_ix, :], X[test_ix, :]\n",
    "    y_tr, y_te = y[train_ix], y[test_ix]\n",
    "\n",
    "    # define search\n",
    "    search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=cv_inner,\n",
    "        n_jobs=8,\n",
    "    )\n",
    "\n",
    "    # execute search\n",
    "    result = search.fit(X_tr, y_tr)\n",
    "\n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    # evaluate model on the hold out dataset\n",
    "    # yhat = best_model.predict(X_te)\n",
    "    yhat = best_model.predict_proba(X_te)[:, 1]\n",
    "\n",
    "    # evaluate the model\n",
    "    roc_auc = roc_auc_score(y_te, yhat)\n",
    "\n",
    "    # store the result\n",
    "    roc_results.append(roc_auc)\n",
    "    found_params.append(result.best_params_)\n",
    "\n",
    "    # report progress\n",
    "    print(\n",
    "        \">roc-auc=%.3f, est=%.3f, params=%s\"\n",
    "        % (roc_auc, result.best_score_, result.best_params_)\n",
    "    )\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"ROC-AUC: %.3f (std = %.3f)\" % (np.mean(roc_results), np.std(roc_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b09b67-5d21-4a6f-8c25-555b57a1e4c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2e3ba-38be-48a4-8b3b-4d41232ed6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_df = pd.DataFrame(roc_results, columns=[\"roc_auc\"])\n",
    "ncv_df = pd.concat([ncv_df, pd.DataFrame(found_params)], axis=1)\n",
    "ncv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b39d9-c9a6-4cfe-b539-f3487fe7bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_df[\"roc_auc\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f5280-9c6a-4363-846a-fa52e31c525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_df[\"roc_auc\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28b068-a06a-4ab0-8b1b-9a4bf0ea3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_df.to_csv(\"./results/svm_ncv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82537001-bac1-4115-8fe9-22891d209049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
