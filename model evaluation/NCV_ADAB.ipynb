{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064996f3-47ed-4554-92f2-0f09ecf16966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import set_config\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 85)\n",
    "sns.set_theme(context=\"paper\", font_scale=1.5, style=\"ticks\", rc={\"axes.grid\": True})\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d33ce1-f62f-438b-a579-dcba06b05091",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AdaBoosting: Scoring by Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6c1ea-489c-4c36-90c9-b4a361d2c506",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4365573-6420-42fc-a153-68caf67a3001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occ_total_sum</th>\n",
       "      <th>oldest_phylostratum</th>\n",
       "      <th>cds_length</th>\n",
       "      <th>dnase_gene</th>\n",
       "      <th>dnase_cds</th>\n",
       "      <th>H3k4me1_gene</th>\n",
       "      <th>H3k4me3_gene</th>\n",
       "      <th>H3k27ac_gene</th>\n",
       "      <th>H3k4me1_cds</th>\n",
       "      <th>H3k4me3_cds</th>\n",
       "      <th>H3k27ac_cds</th>\n",
       "      <th>lamin_gene</th>\n",
       "      <th>repli_gene</th>\n",
       "      <th>nsome_gene</th>\n",
       "      <th>nsome_cds</th>\n",
       "      <th>transcription_gene</th>\n",
       "      <th>repeat_gene</th>\n",
       "      <th>repeat_cds</th>\n",
       "      <th>recomb_gene</th>\n",
       "      <th>AAA_freq</th>\n",
       "      <th>AAC_freq</th>\n",
       "      <th>AAG_freq</th>\n",
       "      <th>AAT_freq</th>\n",
       "      <th>ACA_freq</th>\n",
       "      <th>ACC_freq</th>\n",
       "      <th>ACG_freq</th>\n",
       "      <th>ACT_freq</th>\n",
       "      <th>AGA_freq</th>\n",
       "      <th>AGC_freq</th>\n",
       "      <th>AGG_freq</th>\n",
       "      <th>AGT_freq</th>\n",
       "      <th>ATA_freq</th>\n",
       "      <th>ATC_freq</th>\n",
       "      <th>ATG_freq</th>\n",
       "      <th>ATT_freq</th>\n",
       "      <th>CAA_freq</th>\n",
       "      <th>CAC_freq</th>\n",
       "      <th>CAG_freq</th>\n",
       "      <th>CAT_freq</th>\n",
       "      <th>CCA_freq</th>\n",
       "      <th>CCC_freq</th>\n",
       "      <th>CCG_freq</th>\n",
       "      <th>CCT_freq</th>\n",
       "      <th>CGA_freq</th>\n",
       "      <th>CGC_freq</th>\n",
       "      <th>CGG_freq</th>\n",
       "      <th>CGT_freq</th>\n",
       "      <th>CTA_freq</th>\n",
       "      <th>CTC_freq</th>\n",
       "      <th>CTG_freq</th>\n",
       "      <th>CTT_freq</th>\n",
       "      <th>GAA_freq</th>\n",
       "      <th>GAC_freq</th>\n",
       "      <th>GAG_freq</th>\n",
       "      <th>GAT_freq</th>\n",
       "      <th>GCA_freq</th>\n",
       "      <th>GCC_freq</th>\n",
       "      <th>GCG_freq</th>\n",
       "      <th>GCT_freq</th>\n",
       "      <th>GGA_freq</th>\n",
       "      <th>GGC_freq</th>\n",
       "      <th>GGG_freq</th>\n",
       "      <th>GGT_freq</th>\n",
       "      <th>GTA_freq</th>\n",
       "      <th>GTC_freq</th>\n",
       "      <th>GTG_freq</th>\n",
       "      <th>GTT_freq</th>\n",
       "      <th>TAA_freq</th>\n",
       "      <th>TAC_freq</th>\n",
       "      <th>TAG_freq</th>\n",
       "      <th>TAT_freq</th>\n",
       "      <th>TCA_freq</th>\n",
       "      <th>TCC_freq</th>\n",
       "      <th>TCG_freq</th>\n",
       "      <th>TCT_freq</th>\n",
       "      <th>TGA_freq</th>\n",
       "      <th>TGC_freq</th>\n",
       "      <th>TGG_freq</th>\n",
       "      <th>TGT_freq</th>\n",
       "      <th>TTA_freq</th>\n",
       "      <th>TTC_freq</th>\n",
       "      <th>TTG_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>1488</td>\n",
       "      <td>0.612230</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.561429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216855</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.809254</td>\n",
       "      <td>0.706453</td>\n",
       "      <td>6.798234</td>\n",
       "      <td>0.040516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.026495</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.028533</td>\n",
       "      <td>0.019701</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.028533</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>0.029891</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.019701</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.017663</td>\n",
       "      <td>0.044837</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>0.033967</td>\n",
       "      <td>0.027853</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>873</td>\n",
       "      <td>0.086769</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>0.657839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>0.828752</td>\n",
       "      <td>1.097018</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.043350</td>\n",
       "      <td>0.025258</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>0.024110</td>\n",
       "      <td>0.025258</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.035591</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>0.020666</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.020666</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.026406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.479295</td>\n",
       "      <td>0.611722</td>\n",
       "      <td>0.851369</td>\n",
       "      <td>0.354628</td>\n",
       "      <td>0.618954</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.086996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040463</td>\n",
       "      <td>1.249600</td>\n",
       "      <td>1.354306</td>\n",
       "      <td>6.081620</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868383</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.023408</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.024345</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.024345</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.025281</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.029963</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.034644</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>0.015918</td>\n",
       "      <td>0.031835</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.025281</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.004682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>2800</td>\n",
       "      <td>0.171524</td>\n",
       "      <td>0.280357</td>\n",
       "      <td>0.554023</td>\n",
       "      <td>0.052420</td>\n",
       "      <td>0.278492</td>\n",
       "      <td>0.270357</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.151429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022495</td>\n",
       "      <td>0.921420</td>\n",
       "      <td>1.382249</td>\n",
       "      <td>2.254471</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.143060</td>\n",
       "      <td>0.022054</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>0.022054</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.015546</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.027477</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>0.023861</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.019161</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.014461</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.022054</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.031092</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.015907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1484</td>\n",
       "      <td>0.143843</td>\n",
       "      <td>0.030997</td>\n",
       "      <td>0.400789</td>\n",
       "      <td>0.106455</td>\n",
       "      <td>0.457949</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>0.030997</td>\n",
       "      <td>0.659704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>0.960747</td>\n",
       "      <td>1.196871</td>\n",
       "      <td>1.080241</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.217000</td>\n",
       "      <td>0.039835</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.032280</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.034341</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.011676</td>\n",
       "      <td>0.018544</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.026099</td>\n",
       "      <td>0.018544</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>2649</td>\n",
       "      <td>0.313496</td>\n",
       "      <td>0.427709</td>\n",
       "      <td>0.721323</td>\n",
       "      <td>0.380132</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.371461</td>\n",
       "      <td>0.147603</td>\n",
       "      <td>0.375613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051321</td>\n",
       "      <td>1.156640</td>\n",
       "      <td>1.677763</td>\n",
       "      <td>12.624956</td>\n",
       "      <td>0.019776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549588</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.020634</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.018342</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.014903</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.020634</td>\n",
       "      <td>0.025984</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.030187</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>0.024838</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.016431</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021781</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.028659</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.021781</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.014138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>4035</td>\n",
       "      <td>0.159518</td>\n",
       "      <td>0.305328</td>\n",
       "      <td>0.618466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379258</td>\n",
       "      <td>0.538290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.578686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>0.952004</td>\n",
       "      <td>1.596068</td>\n",
       "      <td>4.338614</td>\n",
       "      <td>0.013269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.271970</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>0.021624</td>\n",
       "      <td>0.012824</td>\n",
       "      <td>0.021624</td>\n",
       "      <td>0.018607</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.018607</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.015841</td>\n",
       "      <td>0.013830</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.023133</td>\n",
       "      <td>0.024642</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>0.009052</td>\n",
       "      <td>0.018104</td>\n",
       "      <td>0.009303</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>0.021121</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.020116</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.018356</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.015841</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.018104</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.018858</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.027910</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.018858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2043</td>\n",
       "      <td>0.164623</td>\n",
       "      <td>0.025453</td>\n",
       "      <td>0.748995</td>\n",
       "      <td>0.710461</td>\n",
       "      <td>0.872609</td>\n",
       "      <td>0.785120</td>\n",
       "      <td>0.786099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>0.865913</td>\n",
       "      <td>1.245576</td>\n",
       "      <td>7.591840</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.458350</td>\n",
       "      <td>0.024463</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.024463</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.016975</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.024463</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.024963</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.025462</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.024963</td>\n",
       "      <td>0.031952</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.033450</td>\n",
       "      <td>0.018972</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>0.034448</td>\n",
       "      <td>0.011483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>372</td>\n",
       "      <td>0.166620</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.857123</td>\n",
       "      <td>0.861899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017871</td>\n",
       "      <td>1.277585</td>\n",
       "      <td>1.767925</td>\n",
       "      <td>0.136402</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.001840</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.024324</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.024324</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.024324</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.024324</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.016216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.362039</td>\n",
       "      <td>0.633400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789180</td>\n",
       "      <td>0.721653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.511535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047280</td>\n",
       "      <td>2.501995</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>11.936696</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.421960</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.023858</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>0.009645</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.031472</td>\n",
       "      <td>0.013706</td>\n",
       "      <td>0.031980</td>\n",
       "      <td>0.029949</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.019289</td>\n",
       "      <td>0.018782</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>0.039594</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.023350</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>0.026396</td>\n",
       "      <td>0.023350</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.023858</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.009645</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.029442</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.009137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18170 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       occ_total_sum  oldest_phylostratum  cds_length  dnase_gene  dnase_cds  \\\n",
       "1                 33                   12        1488    0.612230   0.758065   \n",
       "10                28                    1         873    0.086769   0.195876   \n",
       "100               36                    1        1092    0.479295   0.611722   \n",
       "1000             126                    1        2800    0.171524   0.280357   \n",
       "10000             55                    1        1484    0.143843   0.030997   \n",
       "...              ...                  ...         ...         ...        ...   \n",
       "999              208                    1        2649    0.313496   0.427709   \n",
       "9990              88                    1        4035    0.159518   0.305328   \n",
       "9991              37                    2        2043    0.164623   0.025453   \n",
       "9992              14                   12         372    0.166620   0.572581   \n",
       "9993              53                    6        1994    0.362039   0.633400   \n",
       "\n",
       "       H3k4me1_gene  H3k4me3_gene  H3k27ac_gene  H3k4me1_cds  H3k4me3_cds  \\\n",
       "1          0.561429      1.000000      0.216855     0.661290     1.000000   \n",
       "10         0.657839      0.000000      0.000000     0.000000     0.000000   \n",
       "100        0.851369      0.354628      0.618954     0.754579     0.030220   \n",
       "1000       0.554023      0.052420      0.278492     0.270357     0.021429   \n",
       "10000      0.400789      0.106455      0.457949     0.708221     0.030997   \n",
       "...             ...           ...           ...          ...          ...   \n",
       "999        0.721323      0.380132      0.560000     0.371461     0.147603   \n",
       "9990       0.618466      1.000000      0.379258     0.538290     1.000000   \n",
       "9991       0.748995      0.710461      0.872609     0.785120     0.786099   \n",
       "9992       0.857123      0.861899      1.000000     1.000000     1.000000   \n",
       "9993       1.000000      0.789180      0.721653     1.000000     0.266800   \n",
       "\n",
       "       H3k27ac_cds  lamin_gene  repli_gene  nsome_gene  nsome_cds  \\\n",
       "1         0.198925         0.0    0.041809    0.809254   0.706453   \n",
       "10        0.000000         1.0   -0.007148    0.828752   1.097018   \n",
       "100       0.086996         0.0    0.040463    1.249600   1.354306   \n",
       "1000      0.151429         0.0   -0.022495    0.921420   1.382249   \n",
       "10000     0.659704         0.0   -0.000387    0.960747   1.196871   \n",
       "...            ...         ...         ...         ...        ...   \n",
       "999       0.375613         0.0    0.051321    1.156640   1.677763   \n",
       "9990      0.578686         0.0    0.032907    0.952004   1.596068   \n",
       "9991      1.000000         0.0    0.045040    0.865913   1.245576   \n",
       "9992      1.000000         0.0    0.017871    1.277585   1.767925   \n",
       "9993      0.511535         0.0    0.047280    2.501995   2.685192   \n",
       "\n",
       "       transcription_gene  repeat_gene  repeat_cds  recomb_gene  AAA_freq  \\\n",
       "1                6.798234     0.040516         0.0     0.000000  0.004755   \n",
       "10               0.061963     0.002809         0.0     2.043350  0.025258   \n",
       "100              6.081620     0.028404         0.0     0.868383  0.018727   \n",
       "1000             2.254471     0.014520         0.0     1.143060  0.022054   \n",
       "10000            1.080241     0.009545         0.0     4.217000  0.039835   \n",
       "...                   ...          ...         ...          ...       ...   \n",
       "999             12.624956     0.019776         0.0     0.549588  0.016813   \n",
       "9990             4.338614     0.013269         0.0     2.271970  0.019613   \n",
       "9991             7.591840     0.014049         0.0     2.458350  0.024463   \n",
       "9992             0.136402     0.020090         0.0     2.001840  0.018919   \n",
       "9993            11.936696     0.027329         0.0     2.421960  0.004061   \n",
       "\n",
       "       AAC_freq  AAG_freq  AAT_freq  ACA_freq  ACC_freq  ACG_freq  ACT_freq  \\\n",
       "1      0.008152  0.007473  0.002717  0.011549  0.026495  0.010870  0.008152   \n",
       "10     0.019518  0.021814  0.024110  0.025258  0.018370  0.003444  0.012629   \n",
       "100    0.012172  0.023408  0.003745  0.017790  0.024345  0.007491  0.014981   \n",
       "1000   0.014823  0.022415  0.024946  0.022054  0.014100  0.006146  0.015546   \n",
       "10000  0.015797  0.030220  0.025412  0.024038  0.012363  0.002747  0.019918   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.015285  0.020634  0.015667  0.029041  0.018342  0.012228  0.012992   \n",
       "9990   0.013327  0.021624  0.012824  0.021624  0.018607  0.004275  0.016093   \n",
       "9991   0.007988  0.020469  0.024463  0.015477  0.016975  0.002996  0.011982   \n",
       "9992   0.013514  0.027027  0.024324  0.027027  0.013514  0.008108  0.018919   \n",
       "9993   0.008122  0.012690  0.002538  0.009137  0.023858  0.015736  0.012183   \n",
       "\n",
       "       AGA_freq  AGC_freq  AGG_freq  AGT_freq  ATA_freq  ATC_freq  ATG_freq  \\\n",
       "1      0.010190  0.028533  0.019701  0.009511  0.000679  0.006114  0.010870   \n",
       "10     0.035591  0.009185  0.016073  0.006889  0.016073  0.017222  0.010333   \n",
       "100    0.024345  0.020599  0.025281  0.011236  0.003745  0.013109  0.019663   \n",
       "1000   0.024946  0.016992  0.012292  0.015907  0.013377  0.021330  0.026392   \n",
       "10000  0.048077  0.006868  0.015797  0.009615  0.020604  0.009615  0.032280   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.022163  0.018724  0.019488  0.009171  0.007642  0.014903  0.015667   \n",
       "9990   0.018607  0.016847  0.015841  0.013830  0.007292  0.016595  0.025396   \n",
       "9991   0.017474  0.017474  0.008987  0.014978  0.012481  0.019970  0.024463   \n",
       "9992   0.032432  0.013514  0.013514  0.008108  0.002703  0.027027  0.027027   \n",
       "9993   0.013198  0.025888  0.018274  0.009645  0.001015  0.007614  0.013198   \n",
       "\n",
       "       ATT_freq  CAA_freq  CAC_freq  CAG_freq  CAT_freq  CCA_freq  CCC_freq  \\\n",
       "1      0.002038  0.009511  0.019022  0.028533  0.007473  0.027174  0.031250   \n",
       "10     0.033295  0.019518  0.011481  0.020666  0.022962  0.017222  0.008037   \n",
       "100    0.004682  0.017790  0.016854  0.029963  0.017790  0.034644  0.022472   \n",
       "1000   0.017715  0.026392  0.011931  0.027477  0.017354  0.023861  0.016992   \n",
       "10000  0.023352  0.019918  0.012363  0.021978  0.015797  0.015110  0.003434   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.015667  0.020634  0.025984  0.026366  0.012992  0.026748  0.023691   \n",
       "9990   0.016847  0.019361  0.019864  0.020619  0.023133  0.024642  0.014835   \n",
       "9991   0.019471  0.017474  0.015976  0.024963  0.018472  0.021468  0.012481   \n",
       "9992   0.018919  0.029730  0.018919  0.013514  0.024324  0.035135  0.016216   \n",
       "9993   0.004569  0.010152  0.021320  0.031472  0.013706  0.031980  0.029949   \n",
       "\n",
       "       CCG_freq  CCT_freq  CGA_freq  CGC_freq  CGG_freq  CGT_freq  CTA_freq  \\\n",
       "1      0.025136  0.029891  0.015625  0.027174  0.019701  0.009511  0.007473   \n",
       "10     0.002296  0.021814  0.003444  0.001148  0.004592  0.002296  0.008037   \n",
       "100    0.010300  0.028090  0.005618  0.010300  0.014045  0.003745  0.015918   \n",
       "1000   0.006508  0.019161  0.005785  0.003977  0.007954  0.003977  0.006146   \n",
       "10000  0.004121  0.013049  0.005495  0.001374  0.002060  0.002060  0.013736   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.009935  0.021016  0.009171  0.007642  0.008789  0.007642  0.009935   \n",
       "9990   0.009052  0.018104  0.009303  0.004275  0.007040  0.003017  0.012069   \n",
       "9991   0.003994  0.025462  0.004493  0.004493  0.003994  0.003495  0.014978   \n",
       "9992   0.002703  0.016216  0.005405  0.005405  0.005405  0.005405  0.013514   \n",
       "9993   0.015736  0.028934  0.014721  0.019289  0.018782  0.005076  0.008629   \n",
       "\n",
       "       CTC_freq  CTG_freq  CTT_freq  GAA_freq  GAC_freq  GAG_freq  GAT_freq  \\\n",
       "1      0.017663  0.044837  0.013587  0.008832  0.021739  0.031250  0.008152   \n",
       "10     0.019518  0.022962  0.019518  0.033295  0.013777  0.019518  0.011481   \n",
       "100    0.015918  0.033708  0.011236  0.014981  0.022472  0.026217  0.009363   \n",
       "1000   0.010846  0.025307  0.015907  0.022415  0.022777  0.016269  0.018800   \n",
       "10000  0.014423  0.014423  0.013736  0.034341  0.017857  0.024725  0.024725   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.017577  0.030187  0.012610  0.024838  0.019870  0.022545  0.016431   \n",
       "9990   0.015590  0.021121  0.022630  0.020116  0.014332  0.019361  0.016595   \n",
       "9991   0.020969  0.024963  0.031952  0.021468  0.008987  0.010484  0.014978   \n",
       "9992   0.010811  0.024324  0.016216  0.035135  0.016216  0.021622  0.010811   \n",
       "9993   0.019797  0.039594  0.014721  0.013198  0.021320  0.024365  0.006599   \n",
       "\n",
       "       GCA_freq  GCC_freq  GCG_freq  GCT_freq  GGA_freq  GGC_freq  GGG_freq  \\\n",
       "1      0.016984  0.033967  0.027853  0.034647  0.023777  0.030571  0.029212   \n",
       "10     0.014925  0.006889  0.000000  0.012629  0.018370  0.011481  0.017222   \n",
       "100    0.015918  0.031835  0.007491  0.025281  0.028090  0.029026  0.021536   \n",
       "1000   0.015184  0.016992  0.004700  0.014461  0.017354  0.010484  0.010123   \n",
       "10000  0.016484  0.006868  0.002747  0.006181  0.022665  0.013049  0.010302   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.010699  0.021781  0.005732  0.018724  0.022927  0.014520  0.011846   \n",
       "9990   0.016595  0.015590  0.004275  0.018356  0.019613  0.015841  0.016093   \n",
       "9991   0.013979  0.013979  0.001498  0.021468  0.014978  0.011982  0.009486   \n",
       "9992   0.008108  0.016216  0.005405  0.010811  0.018919  0.016216  0.005405   \n",
       "9993   0.023350  0.032995  0.019797  0.025381  0.024365  0.026396  0.023350   \n",
       "\n",
       "       GGT_freq  GTA_freq  GTC_freq  GTG_freq  GTT_freq  TAA_freq  TAC_freq  \\\n",
       "1      0.013587  0.000679  0.012908  0.027174  0.003397  0.000000  0.008152   \n",
       "10     0.018370  0.005741  0.008037  0.012629  0.012629  0.012629  0.014925   \n",
       "100    0.013109  0.008427  0.010300  0.016854  0.003745  0.006554  0.012172   \n",
       "1000   0.011931  0.009400  0.007231  0.020607  0.011931  0.013738  0.008315   \n",
       "10000  0.008242  0.009615  0.004808  0.013736  0.011676  0.018544  0.012363   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.012992  0.004968  0.011846  0.017577  0.007642  0.006878  0.011846   \n",
       "9990   0.014835  0.008046  0.011064  0.019361  0.010561  0.008801  0.011567   \n",
       "9991   0.007489  0.004993  0.010484  0.012981  0.012981  0.013979  0.014478   \n",
       "9992   0.010811  0.010811  0.010811  0.013514  0.008108  0.000000  0.018919   \n",
       "9993   0.012690  0.003046  0.011168  0.023858  0.008629  0.001523  0.009645   \n",
       "\n",
       "       TAG_freq  TAT_freq  TCA_freq  TCC_freq  TCG_freq  TCT_freq  TGA_freq  \\\n",
       "1      0.000000  0.001359  0.008832  0.021739  0.009511  0.010190  0.020380   \n",
       "10     0.006889  0.017222  0.017222  0.016073  0.005741  0.022962  0.020666   \n",
       "100    0.005618  0.008427  0.014981  0.016854  0.009363  0.008427  0.014981   \n",
       "1000   0.006146  0.016631  0.022054  0.018077  0.004700  0.009038  0.031092   \n",
       "10000  0.008242  0.019231  0.015110  0.012363  0.002060  0.015797  0.024038   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "999    0.003057  0.007642  0.019488  0.017195  0.005732  0.017577  0.028659   \n",
       "9990   0.006035  0.012321  0.019864  0.018104  0.006035  0.018858  0.022630   \n",
       "9991   0.005991  0.016475  0.025961  0.019970  0.006490  0.033450  0.018972   \n",
       "9992   0.005405  0.013514  0.016216  0.024324  0.005405  0.018919  0.029730   \n",
       "9993   0.001015  0.002030  0.012690  0.019797  0.006599  0.016751  0.013198   \n",
       "\n",
       "       TGC_freq  TGG_freq  TGT_freq  TTA_freq  TTC_freq  TTG_freq  \n",
       "1      0.027174  0.029212  0.010870  0.000679  0.013587  0.005435  \n",
       "10     0.012629  0.027555  0.011481  0.021814  0.017222  0.026406  \n",
       "100    0.019663  0.029026  0.010300  0.004682  0.010300  0.004682  \n",
       "1000   0.019523  0.019523  0.016992  0.016269  0.014100  0.015907  \n",
       "10000  0.010989  0.026099  0.018544  0.014423  0.015797  0.019231  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "999    0.015667  0.021781  0.011464  0.006496  0.015667  0.014138  \n",
       "9990   0.017098  0.027910  0.016093  0.011315  0.019613  0.018858  \n",
       "9991   0.015976  0.021468  0.014978  0.018472  0.034448  0.011483  \n",
       "9992   0.005405  0.027027  0.018919  0.010811  0.016216  0.016216  \n",
       "9993   0.029442  0.025888  0.017766  0.001523  0.017259  0.009137  \n",
       "\n",
       "[18170 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data (NEW from PP)\n",
    "df = pd.read_csv(\"../data/new_abnormal_writeout_noscale.data.csv\", index_col=0)\n",
    "\n",
    "# Drop NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Collect Features and Labels\n",
    "features_df = pd.DataFrame()\n",
    "conf = df.drop(labels=[\"response\", \"occ_total_sum\", \"oldest_phylostratum\"], axis=1)\n",
    "\n",
    "features_df[\"occ_total_sum\"] = df[\"occ_total_sum\"]\n",
    "features_df[\"oldest_phylostratum\"] = df[\"oldest_phylostratum\"]\n",
    "features_df = pd.concat([features_df, conf], axis=1)\n",
    "\n",
    "X = features_df.to_numpy()\n",
    "y = df[\"response\"].to_numpy()\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690b20f-f034-48ab-8577-c1b6bd92da19",
   "metadata": {
    "tags": []
   },
   "source": [
    "*** \n",
    "## Nested CV on Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c93d3e-907f-4bc1-a47e-f2d559c0a2d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Model and its Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "108c2358-5fe5-4353-aa6e-81794afcb2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 {color: black;background-color: white;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 pre{padding: 0;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-toggleable {background-color: white;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-estimator:hover {background-color: #d4ebff;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-item {z-index: 1;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-parallel-item:only-child::after {width: 0;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-c208f004-5c0a-4a1c-b529-1504f2ec6828 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-c208f004-5c0a-4a1c-b529-1504f2ec6828\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;ots+of&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [0, 1]),\n",
       "                                                 (&#x27;conf&#x27;, PCA(),\n",
       "                                                  slice(2, 82, None))])),\n",
       "                (&#x27;gb&#x27;, AdaBoostClassifier())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"abeac0fb-de10-4d0f-a7d8-48db25b69a3c\" type=\"checkbox\" ><label for=\"abeac0fb-de10-4d0f-a7d8-48db25b69a3c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;ots+of&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [0, 1]),\n",
       "                                                 (&#x27;conf&#x27;, PCA(),\n",
       "                                                  slice(2, 82, None))])),\n",
       "                (&#x27;gb&#x27;, AdaBoostClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"71316f12-abac-430f-ba0e-74c017bf36cf\" type=\"checkbox\" ><label for=\"71316f12-abac-430f-ba0e-74c017bf36cf\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"790c646e-1d02-4d7a-aff2-e2eb66469598\" type=\"checkbox\" ><label for=\"790c646e-1d02-4d7a-aff2-e2eb66469598\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pca: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;ots+of&#x27;, &#x27;passthrough&#x27;, [0, 1]),\n",
       "                                (&#x27;conf&#x27;, PCA(), slice(2, 82, None))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4e3026de-2ef9-4ac0-9a4c-68b647c7b784\" type=\"checkbox\" ><label for=\"4e3026de-2ef9-4ac0-9a4c-68b647c7b784\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ots+of</label><div class=\"sk-toggleable__content\"><pre>[0, 1]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7de1a178-0828-40f3-94d9-145ccce65497\" type=\"checkbox\" ><label for=\"7de1a178-0828-40f3-94d9-145ccce65497\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9c74efb2-52ad-4b35-a5bf-ad6316719813\" type=\"checkbox\" ><label for=\"9c74efb2-52ad-4b35-a5bf-ad6316719813\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">conf</label><div class=\"sk-toggleable__content\"><pre>slice(2, 82, None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7727b95b-6df6-436b-a05d-d02a7508d378\" type=\"checkbox\" ><label for=\"7727b95b-6df6-436b-a05d-d02a7508d378\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0b6479f5-dc5a-47bf-b1c4-b8ebd1ebb85f\" type=\"checkbox\" ><label for=\"0b6479f5-dc5a-47bf-b1c4-b8ebd1ebb85f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('pca',\n",
       "                 ColumnTransformer(transformers=[('ots+of', 'passthrough',\n",
       "                                                  [0, 1]),\n",
       "                                                 ('conf', PCA(),\n",
       "                                                  slice(2, 82, None))])),\n",
       "                ('gb', AdaBoostClassifier())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Confounder PCA\n",
    "confpca = ColumnTransformer([\n",
    "    (\"ots+of\", \"passthrough\", [0, 1]), \n",
    "    (\"conf\", PCA(), slice(2, X.shape[1]))\n",
    "])\n",
    "\n",
    "# Parameter Grid\n",
    "main_params = {\n",
    "    \"gb__learning_rate\": [0.5, 1, 1.5],\n",
    "    \"gb__n_estimators\": [50, 100, 200],\n",
    "}\n",
    "\n",
    "pca_on = {'pca': [confpca], 'pca__conf__n_components': [None, 0.01, 0.95]}\n",
    "pca_off = {'pca': ['passthrough'],}\n",
    "\n",
    "param_grid = [{**main_params, **pca_on}, {**main_params, **pca_off}]\n",
    "\n",
    "# Define the model to be tuned\n",
    "adab_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", confpca),\n",
    "    (\"gb\", AdaBoostClassifier()),\n",
    "])\n",
    "\n",
    "adab_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275a4f5-142b-4d1e-9e10-516b8c2b63b3",
   "metadata": {},
   "source": [
    "### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c299221a-7dd3-45c8-8f0d-a4bfe362100c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing nested-cv with 10 outer-folds and 5 inner-folds.\n",
      "\n",
      "OUTER CV | BEST OF INNER CV | CHOSEN PARAMS\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcv_inner, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# execute search\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# get the best performing model fit on the whole training set\u001b[39;00m\n\u001b[1;32m     39\u001b[0m best_model \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, RepeatedKFold\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "np.random.seed(3)\n",
    "model = adab_clf\n",
    "k_outer = 10\n",
    "k_inner = 3\n",
    "cv_outer = KFold(n_splits=k_outer, shuffle=True, random_state=1)\n",
    "cv_inner = KFold(n_splits=k_inner, shuffle=True, random_state=3)\n",
    "\n",
    "# To store results\n",
    "roc_results = list()\n",
    "found_params = list()\n",
    "\n",
    "print(f\"Performing nested-cv with {k_outer} outer-folds and {k_inner} inner-folds.\\n\")\n",
    "print(\"OUTER CV | BEST OF INNER CV | CHOSEN PARAMS\")\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "\n",
    "    # split data\n",
    "    X_tr, X_te = X[train_ix, :], X[test_ix, :]\n",
    "    y_tr, y_te = y[train_ix], y[test_ix]\n",
    "\n",
    "    # If some parameter combinations are incompatible:\n",
    "    # with ignore_warnings(category=[ConvergenceWarning, FitFailedWarning]):\n",
    "    \n",
    "    # define search\n",
    "    search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=\"roc_auc\", cv=cv_inner, n_jobs=4)\n",
    "    \n",
    "    # execute search\n",
    "    result = search.fit(X_tr, y_tr)\n",
    "        \n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    # evaluate model on the hold out dataset\n",
    "    # yhat = best_model.predict(X_te)\n",
    "    yhat = best_model.predict_proba(X_te)[:,1]\n",
    "\n",
    "    # evaluate the model\n",
    "    roc_auc = roc_auc_score(y_te, yhat)\n",
    "    \n",
    "    # store the result\n",
    "    roc_results.append(roc_auc)\n",
    "    found_params.append(result.best_params_)\n",
    "\n",
    "    # report progress\n",
    "    print(\">roc-auc=%.3f, est=%.3f, params=%s\" % (roc_auc, result.best_score_, result.best_params_))\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"ROC-AUC: %.3f (std = %.3f)\" % (np.mean(roc_results), np.std(roc_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03170d36-4921-45c1-8f54-62de3c36c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>gb__learning_rate</th>\n",
       "      <th>pca__apply_PCA</th>\n",
       "      <th>pca__n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676146</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703986</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693924</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.688165</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.691082</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.685935</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656577</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.711407</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.667781</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    roc_auc  gb__learning_rate  pca__apply_PCA  pca__n_components\n",
       "0  0.676146               0.10           False               0.95\n",
       "1  0.703986               0.05           False               0.95\n",
       "2  0.683600               0.05           False               0.95\n",
       "3  0.693924               0.05           False               0.95\n",
       "4  0.688165               0.05           False               0.95\n",
       "5  0.691082               0.05           False               0.95\n",
       "6  0.685935               0.05           False               0.95\n",
       "7  0.656577               0.05           False               0.95\n",
       "8  0.711407               0.05           False               0.95\n",
       "9  0.667781               0.05           False               0.95"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncv_df = pd.DataFrame(roc_results, columns=['roc_auc'])\n",
    "ncv_df = pd.concat([ncv_df, pd.DataFrame(found_params)], axis=1)\n",
    "ncv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110059e7-a631-4a4e-841d-ba32ae2e09cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6858603438495539"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncv_df[\"roc_auc\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d5e7ad-6cf0-40f4-9bc6-e9e3c5e7f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_df.to_csv(\"./data/gb_ncv.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
